pro verx, x, _extra=e
	tam = !y.crange
 	ymin = tam(0)
 	ymax = tam(1)
 	if (!y.type eq 1) then begin
   	ymin = 10.d0^tam(0)
      ymax = 10.d0^tam(1)
 	endif
 	plots,x,ymin
 	plots,x,ymax,/continue, _extra=e
end

;**********************************
; Return the perc percetile of an array
;**********************************
function percentile, data, perc
	sidx = sort(data)
	ndata = n_elements(data)
	return, data[sidx[perc*ndata / 100]]
end

;**********************************
; Calculate the histogram of an array
;**********************************
function histog, a, nbins=nbins, binsize=binsize, plot=plot, optimbin=optimbin, min=min, max=max, _extra=_extra
	if (not keyword_set(min)) then begin
		mina = min(a)
	endif else begin
		mina = min
	endelse
	if (not keyword_set(max)) then begin
		maxa = max(a)
	endif else begin
		maxa = max
	endelse
	if (keyword_set(optimbin)) then begin
		binopt = optbin(a)
		h = histogram(a,binsize=binopt,min=mina,max=maxa)
		n = n_elements(h)
		x = findgen(n) * binopt + mina
		if (keyword_set(plot)) then begin
	 		plot,x,h, psym=10, _extra=_extra
	 	endif
		return,[[x],[h]]
	endif
		
	if (keyword_set(nbins)) then begin
		h = histogram(a,nbins=nbins,min=mina,max=maxa)	 
	 	x = findgen(nbins)/(nbins-1.d0) * (maxa-mina) + mina
	 	if (keyword_set(plot)) then begin
	 		plot,x,h, psym=10, _extra=_extra
	 	endif
	 	return,[[x],[h]]
	endif
	 
	if (keyword_set(binsize)) then begin
		h = histogram(a,binsize=binsize,min=mina,max=maxa)
		n = n_elements(h)
		x = findgen(n) * binsize + mina
		if (keyword_set(plot)) then begin
	 		plot,x,h, psym=10, _extra=_extra
	 	endif
		return,[[x],[h]]
	endif
	 	 
end


; *****************************************
; Activation function for the neural network
; *****************************************
function sigma, x	
	return, tanh(x)
end


; *****************************************
; Evaluate a neural network given by the structure neuralnet and applied to a
; vector of input parameters
; *****************************************
function eval_neuralnetwork, neuralnet, input_data

	ndata = n_elements(input_data[0,*])
	ndim = n_elements(input_data[*,0])

	ninput = neuralnet.ninput
	nhidden = (*neuralnet.nhidden)
	noutput = neuralnet.noutput

	output = dblarr(noutput,ndata)
				
	for loop_input = 0L, ndata-1 do begin
		hidden = dblarr(nhidden)
		for i = 0, nhidden-1 do begin
			for j = 0, ninput-1 do begin
				hidden[i] = hidden[i] + (*neuralnet.input_hidden)[j,i] * input_data[j,loop_input]
			endfor
			hidden[i] = sigma(hidden[i] + (*neuralnet.bias)[i])
		endfor
		
		
		for i = 0, noutput-1 do begin
			for j = 0, nhidden-1 do begin
				output[i,loop_input] = output[i,loop_input] + (*neuralnet.hidden_output)[j,i] * hidden[j]
			endfor
		endfor
	endfor
	
	return, output
end

; *****************************************
; Return the SED for a given combination of parameters by using the
; interpolation neural network
; *****************************************
function neural_SED, neural, sigma, Y, N, q, tauv, angle, include_agn=include_agn, jansky=jansky,$
	out_agn = out_agn
	pars = 1.d0*[sigma, Y, N, q, tauv, angle]

	pars_normalized = pars

	PCA_coeffs = fltarr(neural.Nnets)
	output = neural.lambda * 0.d0

 	for loopnet = 0, neural.Nnets-1 do begin
 	
; Normalize input for this network
		for j = 0, neural.net[loopnet].ninput-1 do begin
			pars_normalized[j,*] = (pars[j,*]-neural.net[loopnet].input_mean[j]) / neural.net[loopnet].input_norm[j]
		endfor

; Use neural network to obtain PCA coefficients
		PCA_coeff = eval_neuralnetwork(neural.net[loopnet], pars_normalized)

; Apply inverse normalization
		PCA_coeff[0] = PCA_coeff[0] * neural.net[loopnet].output_norm + $
			neural.net[loopnet].output_mean

; Add coefficient times the eigenvector
		output = output + PCA_coeff[0] * neural.net[loopnet].PCAvector

	endfor

	factor = 1.d0
	if (keyword_set(jansky)) then begin
		c = 2.99792458d10
		factor = (neural.lambda*1.d-4 / c) / 1.d-26
	endif

; Add the mean SED and reverse the initial transformation to log10
	res = 10.d0^(output + neural.meanSED)
	
; If the AGN emission is included...
	if (keyword_set(include_agn)) then begin
		out_agn = lambda_flambda_agn(neural.lambda, 0.2784)
		res = res + out_agn
	endif
	
; Finally, transform to mJy
	return, factor*res
	
end

;-----------------------------------------
; Calculates the ratio Ltorus/Lagn
; file: root of the file with the Markov chains
; file_neural: points to the neural.idl file that is generated by Bayesclumpy
; dist: distance in Mpc
;-----------------------------------------
pro Ltorus_Lagn, file, file_neural, dist
	
; Read the Markov chains
	nparam = 9
	openr,2,file+'post_equal_weights.dat',error=err
	if (err ne 0) then begin
		res = dialog_message('Error opening posterior samples.'+string(10B)+$
			'You should run again the inference',/error)
		return
	endif else begin
		nlength = file_lines(file+'post_equal_weights.dat')
		chain = fltarr(nparam+1,nlength)		
		readf,2,chain
		logposterior = reform(chain[nparam,*])
		chain = chain[0:nparam-1,*]
		close,2
	endelse

; Calculate AGN luminosity
	shif = chain[6,*]
	t1 = 1.0d0*10.d0^(-10.d0+shif)
	t2 = t1*4.*!pi*dist^2 ; dd in Mpc
	Lagn = t2*10^(0.98)*1.d48
	
; Read information about the neural networks
	restore,file_neural
	
	Fbol = fltarr(nlength)
	   
	for i = 0, nlength-1 do begin
	   
		SED_noAGN = neural_SED(neural, chain[0,i], chain[1,i], chain[2,i], chain[3,i], $
			chain[4,i], chain[5,i], include_agn=0, /jansky) / 1.d10 * 10.d0^chain[6,i]
	
		Fbol[i] = tsum(neural.lambda*1.d-4,sed_noagn*3.d10/(neural.lambda*1.d-4)^2) * 1.d-26
	endfor
	
	d = dist * 3.08506d18 * 1.d6
	lbol = Fbol * 4 * !dpi * d^2
	
	r = Lbol / Lagn
	
	h = histog(r, nbin=40)
	plot, h[*,0], h[*,1] / max(h[*,1]), xtit='Covering factor', ytit='Normalized posterior', psym=10
	perc = percentile(r, [50.d0 - 50.d0*erf(1.d0/sqrt(2.d0)), 50.d0, 50.d0 + 50.d0*erf(1.d0/sqrt(2.d0))])
	verx, perc[0], line=1
	verx, perc[1], line=0
	verx, perc[2], line=1
	print, 'Apparent covering factor'
	print, 'Distance [Mpc] = ', dist
	print, 'Median = ', perc[1]
	print, '-1sigma = ', perc[1]-perc[0]
	print, '+1sigma = ', perc[2]-perc[1]
	stop
end
